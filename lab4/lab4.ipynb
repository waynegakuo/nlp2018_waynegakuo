{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# import NP as NP\n",
    "from pylab import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "# Train classifiers while normalizing text\n",
    "################################################################################################################\n",
    "file_to_read = \"train_data.txt\"  # file to be read\n",
    "\n",
    "\n",
    "def train():\n",
    "    # setting the data-set into a data-frame for easy management and manipulation using pandas\n",
    "    doc = pd.read_csv(file_to_read, sep='\\t', names=['review', 'sentiment'])\n",
    "    # print(doc.tail())\n",
    "\n",
    "    # stop words such as 'a', 'is', 'are' are not significant to the corpus for analysis and therefore\n",
    "    # are stripped from the data set\n",
    "    wordset = set(stopwords.words('english'))\n",
    "\n",
    "    # Transforms text to feature vectors that can be used as input to estimator.\n",
    "    v = TfidfVectorizer(use_idf=True, lowercase=True, strip_accents='ascii', stop_words=wordset)\n",
    "\n",
    "    class_categ = doc.sentiment  # positive and negative classes\n",
    "\n",
    "    token = v.fit_transform(doc.review)  # tokenizing the reviews provided in the data-set\n",
    "\n",
    "    # print(class_categ.shape)  # number of observations/reviews\n",
    "    # print(token.shape)  # number of unique words after tokenizing\n",
    "\n",
    "    # Splits the class_categ and token arrays into random train and test subsets\n",
    "    token_train, token_test, class_train, class_test = train_test_split(token, class_categ, random_state=40)\n",
    "\n",
    "    # training the naive bayes classifier\n",
    "    naive_train = naive_bayes.MultinomialNB()\n",
    "    naive_train.fit(token_train, class_train)\n",
    "\n",
    "    # training the logistic regression classifier\n",
    "    log_train = LogisticRegression(penalty='l2', C=1)\n",
    "    log_train.fit(token_train, class_train)\n",
    "\n",
    "    print(\"Logistic Regression classifier accuracy with normalized data is %2.2f\"\n",
    "          % accuracy_score(class_test, log_train.predict(token_test)))\n",
    "\n",
    "    print(\"Naive Bayes classifier accuracy with normalized data is %2.2f\"\n",
    "          % accuracy_score(class_test, naive_train.predict(token_test)))\n",
    "\n",
    "    return naive_train, log_train, v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################################\n",
    "# Train classifiers without normalizing text\n",
    "################################################################################################################\n",
    "\n",
    "def train_u():\n",
    "    # Not normalizing/tokenizing text\n",
    "    vu = TfidfVectorizer(use_idf=False, lowercase=False)\n",
    "\n",
    "    # setting the data-set into a data-frame for easy management and manipulation using pandas\n",
    "    doc = pd.read_csv(file_to_read, sep='\\t', names=['review', 'sentiment'])\n",
    "\n",
    "    class_categ_u = doc.sentiment  # positive and negative classes\n",
    "    token_u = vu.fit_transform(doc.review)\n",
    "\n",
    "    # Splits the class_categ and token arrays into random train and test subsets\n",
    "    token_u_train, token_u_test, class_u_train, class_u_test = train_test_split(token_u, class_categ_u, random_state=40)\n",
    "\n",
    "    # training the naive bayes classifier\n",
    "    naive_train_u = naive_bayes.MultinomialNB()\n",
    "    naive_train_u.fit(token_u_train, class_u_train)\n",
    "\n",
    "    # training the logistic regression classifier\n",
    "    log_train_u = LogisticRegression(penalty='l2', C=1)\n",
    "    log_train_u.fit(token_u_train, class_u_train)\n",
    "\n",
    "    print(\"Logistic Regression classifier accuracy with unnormalized data is %2.2f\"\n",
    "          % accuracy_score(class_u_test, log_train_u.predict(token_u_test)))\n",
    "\n",
    "    print(\"Naive Bayes classifier accuracy with unnormalized data is %2.2f\"\n",
    "          % roc_auc_score(class_u_test, naive_train_u.predict(token_u_test)))\n",
    "\n",
    "    return naive_train_u, log_train_u, vu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "# Testing with normalized data\n",
    "###################################################################################################################\n",
    "\n",
    "def nb(cl, mod, test_file):\n",
    "    naive_train, log_train, v = train()\n",
    "    file = open(test_file, \"r\")\n",
    "    predict_array = []  # initialize array to contain classifier results\n",
    "    for line in file:\n",
    "        # treating each line by putting them into an array using an inbuilt panda function\n",
    "        movie_review_arr = pd.np.array([line])\n",
    "        movie_vect = v.transform(movie_review_arr)\n",
    "        class_placed = naive_train.predict(movie_vect)\n",
    "\n",
    "        # putting the classification results into an array\n",
    "        predict_array.append(class_placed)\n",
    "\n",
    "    f = open(\"results-nb-n.txt\", \"w\")\n",
    "\n",
    "    # writing the results into a text file\n",
    "    for item in predict_array:\n",
    "        res = str(item)\n",
    "        f.write(res.strip('[]') + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def lr(cl, mod, test_file):\n",
    "    naive_train, log_train, v = train()\n",
    "    file = open(test_file, \"r\")\n",
    "    lr_predict_array = []  # initialize array to contain classifier results\n",
    "    for line in file:\n",
    "        # treating each line by putting them into an array using an inbuilt panda function\n",
    "        movie_review_arr = pd.np.array([line])\n",
    "        movie_vect = v.transform(movie_review_arr)\n",
    "        class_placed = log_train.predict(movie_vect)\n",
    "\n",
    "        # putting the classification results into an array\n",
    "        lr_predict_array.append(class_placed)\n",
    "\n",
    "    f = open(\"results-lr-n.txt\", \"w\")\n",
    "\n",
    "    # writing the results into a text file\n",
    "    for item in lr_predict_array:\n",
    "        res = str(item)\n",
    "        f.write(res.strip('[]') + \"\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################################\n",
    "# Testing with not normalized data\n",
    "###################################################################################################################\n",
    "\n",
    "def nb_u(cl, mod, test_file):\n",
    "    naive_train_u, log_train_u, vu = train_u()\n",
    "    file = open(test_file, \"r\")\n",
    "    predict_array_u = []  # initialize array to contain classifier results\n",
    "    for line in file:\n",
    "        # treating each line by putting them into an array using an inbuilt panda function\n",
    "        movie_review_arr = pd.np.array([line])\n",
    "        movie_vect = vu.transform(movie_review_arr)\n",
    "        class_placed = naive_train_u.predict(movie_vect)\n",
    "\n",
    "        # putting the classification results into an array\n",
    "        predict_array_u.append(class_placed)\n",
    "\n",
    "    f = open(\"results-nb-u.txt\", \"w\")\n",
    "\n",
    "    # writing the results into a text file\n",
    "    for item in predict_array_u:\n",
    "        res = str(item)\n",
    "        f.write(res.strip('[]') + \"\\n\")\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def lr_u(cl, mod, test_file):\n",
    "    naive_train_u, log_train_u, vu = train_u()\n",
    "    file = open(test_file, \"r\")\n",
    "    lr_predict_array_2 = []  # initialize array to contain classifier results\n",
    "    for line in file:\n",
    "        # treating each line by putting them into an array using an inbuilt panda function\n",
    "        movie_review_arr = pd.np.array([line])\n",
    "        movie_vect = vu.transform(movie_review_arr)\n",
    "        class_placed = log_train_u.predict(movie_vect)\n",
    "\n",
    "        # putting the classification results into an array\n",
    "        lr_predict_array_2.append(class_placed)\n",
    "\n",
    "    f = open(\"results-lr-u.txt\", \"w\")\n",
    "\n",
    "    # writing the results into a text file\n",
    "    for item in lr_predict_array_2:\n",
    "        res = str(item)\n",
    "        f.write(res.strip('[]') + \"\\n\")\n",
    "    f.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute \n",
    "\n",
    "# accepting arguments from the command line\n",
    "\n",
    "if sys.argv[1] == \"nb\" and sys.argv[2] == \"n\":\n",
    "    cl = sys.argv[1]\n",
    "    mod = sys.argv[2]\n",
    "    test_file = sys.argv[3]\n",
    "    print(\"\\n\")\n",
    "    print(\"######## Naive Bayes Classifier with Normalized Data ########\")\n",
    "    nb(cl, mod, test_file)\n",
    "\n",
    "elif sys.argv[1] == \"nb\" and sys.argv[2] == \"u\":\n",
    "    cl = sys.argv[1]\n",
    "    mod = sys.argv[2]\n",
    "    test_file = sys.argv[3]\n",
    "    print(\"\\n\")\n",
    "    print(\"######## Naive Bayes Classifier Without Normalized Data ########\")\n",
    "    nb_u(cl, mod, test_file)\n",
    "\n",
    "elif sys.argv[1] == \"lr\" and sys.argv[2] == \"n\":\n",
    "    cl = sys.argv[1]\n",
    "    mod = sys.argv[2]\n",
    "    test_file = sys.argv[3]\n",
    "    print(\"\\n\")\n",
    "    print(\"######## Logistic Regression Classifier With Normalized Data ########\")\n",
    "    lr(cl, mod, test_file)\n",
    "\n",
    "elif sys.argv[1] == \"lr\" and sys.argv[2] == \"u\":\n",
    "    cl = sys.argv[1]\n",
    "    mod = sys.argv[2]\n",
    "    test_file = sys.argv[3]\n",
    "    print(\"\\n\")\n",
    "    print(\"######## Logistic Regression Classifier Without Normalized Data ########\")\n",
    "    lr_u(cl, mod, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
